{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of a Comments to Optimize the Query Resolution.\n",
    "\n",
    "<br>\n",
    "\n",
    "Sentiment analysis is contextual mining of text which identifies and extracts subjective information in the source material and helps a business to understand the social sentiment of their brand, product or service while monitoring online conversations.\n",
    "We are using NLTK for Natural Language Processing. NLTK stands for Natural Language Toolkit. It is a powerful tool complete with different Python modules and libraries to carry out simple to complex natural language processing (NLP). NLTK provides a VADER model to analyse the sentiment of the comments on the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is VADER?\n",
    "\n",
    "<br>\n",
    "\n",
    "VADER ( Valence Aware Dictionary for Sentiment Reasoning) is a model used for text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "VADER sentimental analysis relies on a dictionary that maps lexical features to emotion intensities known as sentiment scores. The sentiment score of a text can be obtained by summing up the intensity of each word in the text.\n",
    "\n",
    "For example- Words like ‚Äòlove‚Äô, ‚Äòenjoy‚Äô, ‚Äòhappy‚Äô, ‚Äòlike‚Äô all convey a positive sentiment. Also VADER is intelligent enough to understand the basic context of these words, such as ‚Äúdid not love‚Äù as a negative statement. It also understands the emphasis of capitalization and punctuation, such as ‚ÄúENJOY‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages\n",
    "\n",
    "<br>\n",
    "\n",
    "Here are the advantages of using VADER which makes a lot of things easier:\n",
    "* It does not require any training data.\n",
    "* It can very well understand the sentiment of a text containing emoticons, slangs, conjunctions, capital words, punctuations and much more.\n",
    "* It works excellent on social media text.\n",
    "* VADER can work with multiple domains.\n",
    "\n",
    "Let‚Äôs start analysing the sentiment using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# For Preprocessing\n",
    "import re\n",
    "\n",
    "# For Natural Language Processing\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Assume that queries on social media such as Twitter received an incremental comments of different types. That may contain possible solutions, scams, promotions or negative feedback about the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Json Data\n",
    "f = open(\"data.json\")\n",
    "data = json.load(f)\n",
    "df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Comments\n",
    "<br>\n",
    "Here, we are preprocessing all the text to remove unnecessary numeric data and stop words to derive more accurate results for the sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Tweet to Clean Text by removing Stop Words to improve Accuracy\n",
    "def tweet_to_words(tweet):\n",
    "    text = tweet.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Comments Text by removing Stop Words and Mentions\n",
    "for d in df[\"data\"]:\n",
    "    for c in d[\"comments\"]:\n",
    "        c[\"cleantext\"] = \" \".join(tweet_to_words(c[\"text\"])[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER's Sentiment Intensity Analyzer\n",
    "\n",
    "<br>\n",
    "\n",
    "VADER‚Äôs `SentimentIntensityAnalyzer()` takes in a string and returns a dictionary of scores in each of four categories:\n",
    "* Negative\n",
    "* Neutral\n",
    "* Positive\n",
    "* Compound\n",
    "\n",
    "The Compound score is the sum of positive, negative & neutral scores which is then normalized between -1(most extreme negative) and +1 (most extreme positive).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the VADER (Valence Aware Dictionary for Sentiment Reasoning) Score\n",
    "def compute_vader_scores(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return {\n",
    "        \"vader_negative\": sid.polarity_scores(text)[\"neg\"],\n",
    "        \"vader_neutral\": sid.polarity_scores(text)[\"neu\"],\n",
    "        \"vader_positive\": sid.polarity_scores(text)[\"pos\"],\n",
    "        \"vader_compound\": sid.polarity_scores(text)[\"compound\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in df[\"data\"]:\n",
    "    for c in d[\"comments\"]:\n",
    "        score = compute_vader_scores(c[\"cleantext\"])\n",
    "        c[\"vader_negative\"] = score.get(\"vader_negative\")\n",
    "        c[\"vader_positive\"] = score.get(\"vader_positive\")\n",
    "        c[\"vader_compound\"] = score.get(\"vader_compound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Comments\n",
    "\n",
    "<br>\n",
    "\n",
    "We are analyzing the comments based on the compound score to get the best possible solution. Here, we are putting a constraint on the compound score to be greater than zero to get the positive sentiment comments. Comment with a big compound score may be the possible solution for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = []\n",
    "for d in df[\"data\"]:\n",
    "    max_compond = 0\n",
    "    a = { \"query\": d[\"text\"], \"solutions\": []}\n",
    "    for c in d[\"comments\"]:\n",
    "        if c[\"vader_compound\"] >= max_compond:\n",
    "            max_compond = c[\"vader_compound\"]\n",
    "    if max_compond > 0:\n",
    "        for c in d[\"comments\"]:\n",
    "            if c[\"vader_compound\"] == max_compond:\n",
    "                a[\"solutions\"].append(c[\"text\"])\n",
    "        analysis.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "<br>\n",
    "\n",
    "We can see the list of possible solutions for a given query. We can improve accuracy by adding advanced processing and intent checks to get the best results. Also, updating the existing knowledge base using this will further improve the accuracy, consistency and performance of the current system to enhance the query resolution of a customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì @lg My LG refrigerator has sheets of ice build up on the bottom every week. Any idea how to fix it?\n",
      "\n",
      "üü¢ @lg @bill There should be a drain that allows the moisture that is generated in the freezer to drain into a pan under the refrigerator where the heat from the compressor will evaporate it. There is a RED button on the back that you can press to fix this. Generally that drain gets clogging and allows the water to accumulate in the freezer and...it freezes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in analysis:\n",
    "    print(\"‚ùì {query}\".format(query = a[\"query\"]))\n",
    "    print()\n",
    "    for s in a[\"solutions\"]:\n",
    "        print(\"üü¢ {solution}\".format(solution = s))\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14c78a8617bb0cefee0b68e304f145219dbd1e1021884fdbae93bea4a88accfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
